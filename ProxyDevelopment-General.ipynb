{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "#import sklearn.externals.joblib as extjoblib\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "#Bayesian optimizer\n",
    "\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "\n",
    "# ANN\n",
    "#Sequential for initializing the neural network\n",
    "#Dense for adding a densely connected neural network layer\n",
    "#LSTM for adding the Long Short-Term Memory layer\n",
    "#Dropout for adding dropout layers that prevent overfitting\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import History\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Paths and version name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path=r\"C:\\Users\\Keras-Model\\\\\"\n",
    "database_path=r\"C:\\Users\\Database\\\\\"\n",
    "Result_path=r\"C:\\Users\\Results\\\\\"\n",
    "version=\"49v4\" \n",
    "\n",
    "# Version of databased used for training and validation of ANN\n",
    "output=\"FOPR\" \n",
    "scalerX_name=\"scalerX_\"+output\n",
    "scalerY_name=\"scalerY_\"+output\n",
    "path_best_model_fwir =  r\"C:\\Users\\Keras-Model\\fwir_Olymp_\"+version+\"_minmax.keras\"\n",
    "path_best_model_fopr =  r\"C:\\Users\\Keras-Model\\fopr_Olymp_\"+version+\"_minmax.keras\"\n",
    "path_best_model_fwpr =  r\"C:\\Users\\Keras-Model\\fwpr_Olymp_\"+version+\"_minmax.keras\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\Database\\Olympus_\"+version+\".csv\",sep=',')\n",
    "#dataset = dataframe.values\n",
    "data.shape\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining ANN model architecture and Data Splitting\n",
    "The keras API has two modes of consturcting neural networks. The simplest is the sequential model which only allows for the layers to be added in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builing ANN Model\n",
    "def ANN_model(X_train, Y_train, learning_rate, dropout, n_units, n_layers):\n",
    "    \n",
    "   #Reset the network graphs for results repdroucability in Keras\n",
    "    N=17 #seed number to give a starting point to random number generate\n",
    "    np.random.seed(N)\n",
    "    rn.seed(N)\n",
    "    session_conf=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "    tf.random.set_seed(N)\n",
    "    K.clear_session()\n",
    "    sess=tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.get_session()\n",
    "    \n",
    "    #start construction of the sequential model\n",
    "    model=Sequential()\n",
    "    if n_layers ==1:\n",
    "        #add a input layer\n",
    "        \n",
    "        model.add(Dense(n_units, activation='relu', input_dim=X_train.shape[1]))\n",
    "    else:\n",
    "        model.add(Dense(n_units, activation='relu', input_dim=X_train.shape[1]))\n",
    "        for i in range(n_layers-1):\n",
    "            model.add(Dense(n_units, activation='relu')) \n",
    "            #ReLU standsfor rectified linear unit, and is a type of activation function. Mathematically, it is defined as y = max(0, x). Visually, it looks like the following: \n",
    "         #ReLU is the most commonly used activation function in neural networks, especially in CNN\n",
    "    #add dropout\n",
    "    model.add(Dropout(dropout))\n",
    "    #Add dense layer\n",
    "    model.add(Dense(Y_train.shape[1], activation='linear'))\n",
    "    #model.add(LeakyRelU(alpha=0.1))\n",
    "    \n",
    "# Neural network has been defined and must be finalized by adding a loss_function, optimizer and performance metrics\n",
    "#This is called \"compilation\" in Keras. One can either define the optimizer using string or if wants to have more control \n",
    "# of its parameters then instantiate an object, like learning_rate in this case.\n",
    "\n",
    "    adam=optimizers.Adam(lr=learning_rate)\n",
    "    # compiling ANN model using adam optimizer and mse loss function\n",
    "    #model.compile(optimizer=adam, loss='mse',metrics=['accuracy','mean_absolute_percentage_error','root_mean_squared_error'])\n",
    "    model.compile(optimizer=adam, loss='mae',metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def data_split(data, feature_list, target, lifetime ):\n",
    "    \"\"\" \n",
    "    Splits data into train, validation and test sets \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Dataframe, shape=[n_points, n_features]\n",
    "    All feature data\n",
    "    feature list : list\n",
    "        list of features to include into training\n",
    "    target: list\n",
    "        List of target variables to include into training\n",
    "    Returns\n",
    "    ------\n",
    "    -Train, validation and test sets, array-like\n",
    "    -scaling functions for X and Y\n",
    "    \"\"\"\n",
    "    X=data[feature_list]\n",
    "    Y=data[target]\n",
    "    \n",
    "    #lifetime is used for entire production cycle of reservoir \n",
    "    split=(X.shape[0])/lifetime\n",
    "    #train_size = int(0.75*X.shape[0])\n",
    "    #test_size = int(0.90*X.shape[0])\n",
    "    train_size = int(0.75*split)*lifetime\n",
    "    test_size = int(0.90*split)*lifetime\n",
    "    #train_size = 504\n",
    "    #test_size = 525\n",
    "    n_target = int(len(target)) #number of target outputs # in this case it give 1 as output\n",
    "    \n",
    "    #splitting\n",
    "#reshape (-1,1) provides column as 1 but rows as unknown , so output will be an array with 1 column and rows as present    \n",
    "    \n",
    "    (X_train, Y_train) =(np.array(X[:train_size]), np.array(Y[:train_size]).reshape(-1, n_target))\n",
    "    (X_val, Y_val) =(np.array(X[train_size:test_size]), np.array(Y[train_size:test_size]).reshape(-1, n_target))\n",
    "    (X_test, Y_test) =(np.array(X[test_size:]), np.array(Y[test_size:]).reshape(-1, n_target))\n",
    "    \n",
    "    #scaling \n",
    "    \n",
    "    scalerX=MinMaxScaler().fit(X_train)\n",
    "    scalerY=MinMaxScaler().fit(Y_train)\n",
    "    joblib.dump(scalerX, keras_model_path+ scalerX_name+version+'.gz')\n",
    "    joblib.dump(scalerY, keras_model_path+ scalerY_name +version+'.gz')\n",
    "    X_train =scalerX.transform(X_train)\n",
    "    Y_train=scalerY.transform(Y_train)\n",
    "    X_val =scalerX.transform(X_val)\n",
    "    Y_val=scalerY.transform(Y_val)\n",
    "    X_test =scalerX.transform(X_test)\n",
    "    Y_test=scalerY.transform(Y_test)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test, scalerX, scalerY, train_size, test_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, Y_train, X_val, Y_val, X_test, Y_test, scalerX_name, scalerY_name, train_size, test_size]= \\\n",
    "data_split(data=data, feature_list=[\"timestep\", \"BHPI1\", \"BHPI2\", \"BHPI3\", \"BHPI4\", \"BHPI5\", \\\n",
    "                                    \"BHPI6\", \"BHPP1\", \"BHPP10\", \"BHPP2\", \"BHPP3\",\"BHPP4\", \"BHPP5\", \\\n",
    "                                    \"BHPP6\", \"BHPP7\",\"BHPP8\", \"BHPP9\"], target=[output], lifetime=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Error distribution and proxy performance function for test_Data\n",
    "\n",
    "def plot_train_performance(model,X_train, Y_train, X_val,Y_val,scalerY):\n",
    "    # model = the ANN model (fitted)\n",
    "    # X_train = input for the ANN from training database\n",
    "    # Y_train = output of the training database\n",
    "    # X_val = input for the ANN from validation database\n",
    "    # Y_val = output of the validation database\n",
    "    # lims = 2 points [min,max] for the plot boundary\n",
    "\n",
    "    # Calculate test data with the model\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_val)\n",
    "    train_preds=scalerY.inverse_transform(train_preds)\n",
    "    val_preds=scalerY.inverse_transform(val_preds)\n",
    "    Y_train=scalerY.inverse_transform(Y_train)\n",
    "    Y_val=scalerY.inverse_transform(Y_val)\n",
    "    # Checking performance of test data\n",
    "    plt.figure(4)\n",
    "    plt.axes(aspect='equal')\n",
    "    plt.scatter(Y_train, train_preds, label='Training')\n",
    "    plt.scatter(Y_val, val_preds, label='Validation', marker='x')\n",
    "    plt.legend()\n",
    "    plt.xlabel('True Values,' + output)\n",
    "    plt.ylabel('Predictions,' + output)\n",
    "    lims=[np.min(Y_val),np.max(Y_val)]\n",
    "    plt.xlim(lims)\n",
    "    plt.ylim(lims)\n",
    "    _ = plt.plot(lims, lims)\n",
    "    \n",
    "    # Getting error distribution\n",
    "    plt.figure(5)\n",
    "    error_train = train_preds - Y_train\n",
    "    error_val = val_preds - Y_val\n",
    "    plt.hist(error_train, bins=25,label='Training')\n",
    "    plt.hist(error_val, bins=25,label='Validation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Prediction Error,'+ output +'[Sm3]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r2_train = r2_score(Y_train, train_preds)\n",
    "    r2_val = r2_score(Y_val, val_preds)\n",
    "    print(\"R-square Training: {:.2f}\".format(r2_train))\n",
    "    print(\"R-square Validation: {:.2f}\".format(r2_val))\n",
    "    ape_train = (abs(Y_train-train_preds))/(Y_train)*100\n",
    "    max_ape_train = max(ape_train)\n",
    "  \n",
    "    mean_ape_train = statistics.mean(ape_train.flatten())\n",
    "    min_ape_train = min(ape_train)\n",
    "    print(\"\"\"Training Average Percentage Error:\n",
    "    - Maximum=%.2f\n",
    "    - Mean=%.2f\n",
    "    - Minimum=%.2f\"\"\" % (max_ape_train, mean_ape_train, min_ape_train))\n",
    "    \n",
    "    # Calculate Validation Absolute Percentage Error (APE)\n",
    "    ape_val = (abs(Y_val-val_preds))/(Y_val)*100\n",
    "    max_ape_val = max(ape_val)\n",
    "    mean_ape_val = statistics.mean(ape_val.flatten())\n",
    "    min_ape_val = min(ape_val)\n",
    "    plt.figure(9)\n",
    "    plt.hist(ape_train,bins=25,label='APE Training')\n",
    "    plt.hist(ape_val,bins=25,label='APE Validation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Absolute Percentage Error,'+ output + '[%]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    \n",
    "    print(\"\"\"Validation Average Percentage Error:\n",
    "    - Maximum=%.2f\n",
    "    - Mean=%.2f\n",
    "    - Minimum=%.2f\"\"\" % (max_ape_val, mean_ape_val, min_ape_val))\n",
    "    \n",
    "    print (\"Train NRMSE is\", np.sqrt(mse(Y_train, train_preds))/np.mean(Y_train)*100)\n",
    "    print (\"Val NRMSE is\", np.sqrt(mse(Y_val, val_preds))/np.mean(Y_val)*100)\n",
    "    \n",
    "def plot_test_performance(model, X_test, Y_test, scalerY):\n",
    "    # model = the ANN model (fitted)\n",
    "    # X_test = input for the ANN from test database\n",
    "    # Y_test = output of the test database\n",
    "    # lims = 2 points [min,max] for the plot boundary\n",
    "\n",
    "    # Calculate test data with the model\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_preds= scalerY.inverse_transform(test_preds)\n",
    "    Y_test=scalerY.inverse_transform(Y_test)\n",
    "    # Checking performance of test data\n",
    "    plt.figure(6)\n",
    "    plt.axes(aspect='equal')\n",
    "    plt.scatter(Y_test, test_preds)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.legend(['Testing'])\n",
    "    lims=[np.min(test_preds),np.max(test_preds)]\n",
    "    plt.xlim(lims)\n",
    "    plt.ylim(lims)\n",
    "    _ = plt.plot(lims, lims)\n",
    "    \n",
    "    # Getting error distribution\n",
    "    plt.figure(7)\n",
    "    error = test_preds - Y_test\n",
    "    plt.hist(error, bins=25,label='Testing')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Prediction Error,'+ output +'[Sm3]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r2_test = r2_score(Y_test, test_preds)\n",
    "    print(\"R-square Test: {:.2f}\".format(r2_test))\n",
    "    \n",
    "    # Calculate Absolute Percentage Error (APE)\n",
    "    ape_test = (abs(Y_test-test_preds))/(Y_test)*100\n",
    "    max_ape_test = max(ape_test)\n",
    "    mean_ape_test = statistics.mean(ape_test.flatten())\n",
    "    min_ape_test = min(ape_test)\n",
    "    plt.figure(10)\n",
    "    plt.hist(ape_test,bins=25,label='APE Test')\n",
    "   \n",
    "    plt.legend()\n",
    "    plt.xlabel('Absolute Percentage Error,'+ output + '[%]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    print(\"\"\"Average Percentage Error:\n",
    "    - Maximum=%.2f\n",
    "    - Mean=%.2f\n",
    "    - Minimum=%.2f\"\"\" % (max_ape_test, mean_ape_test, min_ape_test))    \n",
    "    print (\"Test NRMSE is\", np.sqrt(mse(Y_test, test_preds))/np.mean(Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start=time.time()\n",
    "#default hyperparameters\n",
    "\n",
    "default_parameters = [0.01, 2, 20, 0.1]\n",
    "num_epochs = 1000\n",
    "\n",
    "dim_learning_rate =Real(low=1e-3, high=1e-1, prior='log-uniform', name='learning_rate')\n",
    "dim_n_layers=Integer(low=1, high=5, name='n_layers')\n",
    "dim_n_units= Integer(low=20, high=100, name='n_units')\n",
    "dim_dropout = Real(low=0.01, high=0.1, prior='log-uniform', name='dropout')\n",
    "dimensions = [dim_learning_rate, dim_n_layers, dim_n_units, dim_dropout]\n",
    "\n",
    "path_best_model=path_best_model_fopr\n",
    "best_val_loss = 100.0\n",
    "@use_named_args(dimensions=dimensions)\n",
    "\n",
    "\n",
    "def fitness_SPM(learning_rate, n_layers, n_units, dropout):\n",
    "    \n",
    "    \"\"\"\n",
    " Hyper-parameters:\n",
    "learning_rate: Learning-rate for the optimizer.\n",
    "n_layers: Number of dense layers.\n",
    " n_units: Number of nodes in each dense layer.\n",
    " dropout: Percentage of the nodes retained.\n",
    " window: Number of window\n",
    " \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', n_layers)\n",
    "    print('num_dense_nodes:', n_units)\n",
    "    print('dropout:', dropout)\n",
    "\n",
    "\n",
    "    model= ANN_model(X_train=X_train, Y_train=Y_train, learning_rate=learning_rate,\\\n",
    "                     dropout=dropout, n_units=n_units, n_layers=n_layers)\n",
    "\n",
    "#use Keras to train the model.\n",
    "\n",
    "    patience= 20\n",
    "    es= EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience, restore_best_weights=True)\n",
    "    history= model.fit(X_train, Y_train, verbose=1, epochs=num_epochs, validation_data=(X_val, Y_val), callbacks=[es])\n",
    "\n",
    "# Get the classification accuracy on the validation-set\n",
    "#after the last training-epoch.\n",
    "\n",
    "    if  es.stopped_epoch == 0:\n",
    "        val_loss =history.history['val_loss'][-1]\n",
    "       \n",
    "    else:\n",
    "        val_loss=history.history['val_loss'][es.stopped_epoch-patience]\n",
    "    #Print the classification accuracy.\n",
    "    print()\n",
    "    print('val_loss:', val_loss)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #save the model if it improves on the best-found performance\n",
    "    #we use the global keyword so we update the variable outside of this function\n",
    "    \n",
    "    global best_val_loss\n",
    "    \n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if val_loss + loss < best_val_loss:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "    \n",
    "    # Update the classification accuracy.\n",
    "        best_val_loss = val_loss\n",
    "    \n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    \n",
    "    del model\n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters\n",
    "    K.clear_session()\n",
    "    np.save('history_'+version+output+'.npy', history.history)\n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "     # Because we are interested in the HIGHEST classification\n",
    "     # accuracy, we need to negate this number so it can be minimized\n",
    "    #history=np.load('history_49_fwir.npy',allow_pickle='TRUE').item()\n",
    "   # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    # or save to csv: \n",
    "    hist_df.to_csv('history_'+version+ output +'.csv')\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "# run the hyper-paramter optimization.\n",
    "search_result = gp_minimize(func=fitness_SPM,dimensions=dimensions, acq_func='EI', n_calls=80,x0=default_parameters)\n",
    "\n",
    "plot_convergence(search_result)\n",
    "end=time.time()\n",
    "\n",
    "space = search_result.x #reference to the search-space object\n",
    "space.point_to_dict(search_result.x) #Then we can use it to create a dict where the hyper-parameters have \n",
    "hours, rem=divmod(end-start, 3600)\n",
    "minutes, seconds =divmod(rem, 60)\n",
    "print(\"Time elapsed: \", int(hours), \"hours\", int(minutes), \"minutes\", int(seconds), \"seconds\")\n",
    "\n",
    "# Print best hyperparameter values\n",
    "print(space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution and proxy performance function for test data\n",
    "# load the established model, comment \n",
    "\n",
    "model_fopr=load_model(path_best_model_fopr )\n",
    "#model_fwpr=load_model(path_best_model_fwpr )\n",
    "#model_fwir=load_model(path_best_model_fwir )\n",
    "\n",
    "b=plot_train_performance(model_fopr,X_train,Y_train,X_val,Y_val,scalerY_name)\n",
    "c=plot_test_performance(model_fopr,X_test,Y_test,scalerY_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind Testsing of FOPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_data = pd.read_csv(r\"C:\\Users\\Database\\BlindTest.csv\",sep=',')\n",
    "\n",
    "X_blind=blind_data[[\"timestep\", \"BHPI1\", \"BHPI2\", \"BHPI3\", \"BHPI4\", \"BHPI5\",\\\n",
    "            \"BHPI6\", \"BHPP1\", \"BHPP10\", \"BHPP2\", \"BHPP3\",\"BHPP4\", \"BHPP5\",\\\n",
    "            \"BHPP6\", \"BHPP7\", \"BHPP8\", \"BHPP9\"]]\n",
    "Y_blind_fopr=test_data[[\"FOPR\"]]\n",
    "Y_blind_fopr=np.array(Y_blind_fopr[:]).reshape(-1,1)\n",
    "\n",
    "# load model and invert predictions\n",
    "model_fopr=load_model(path_best_model_fopr )\n",
    "scalerX_fopr=joblib.load( keras_model_path+scalerX_name+'.gz')\n",
    "scalerY_fopr=joblib.load( keras_model_path+ scalerY_name'+'.gz')\n",
    "\n",
    "X_blind=scalerX_fopr.transform(X_blind)\n",
    "Y_blind=scalerY_fopr.transform(Y_blind_fopr)\n",
    "test_preds_fopr=model_fopr.predict(X_blind)\n",
    "test_preds_fopr = scalerY_fopr.inverse_transform(test_preds_fopr)\n",
    "\n",
    "print (\"Blind Test NRMSE is\", np.sqrt(mse(Y_blind_fopr, test_preds_fopr))/np.mean(Y_blind_fopr)*100)\n",
    "\n",
    "xdata = np.arange(1,len(Y_blind_fopr)+1,1)\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "plt.rc('axes', titlesize=20) # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=20) # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=15) # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=15) # fontsize of the tick  labels\n",
    "plt.rc('legend', fontsize=18) # legend fontsize\n",
    "plt.figure(2)\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('FOPR [Sm3/day]')\n",
    "plt.plot(xdata, Y_blind_fopr[:,0], label='Data', color='black', linewidth=3)\n",
    "plt.plot(xdata, test_preds_fopr[:,0], label='Model', linestyle=':', color='black', linewidth=3)\n",
    "plt.legend(['Eclipse', 'SPM'], loc='upper right' )\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "plt.savefig(Result_path+'FOPR Blind Test.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
